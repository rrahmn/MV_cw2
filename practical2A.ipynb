{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIANUR RAHMAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 7 - Part 2A\n",
    "This second half of the lab explores the geometry of a single camera. In 2B the goal is to use a set of correspondance points to estimate a transformation matrix from a plane's 3D space to camera space and use that matrix to project some other points into camera space.\n",
    "\n",
    "In this section, we'll work on building two components that we need for 2B, a method to estimate that transformation and a method that can project points into camera image space.\n",
    "\n",
    "First we'll tackle the projection method, `projectiveCamera`. We want to find the image space coordinates, `XImCart`, of a set of 3D world coordinates, `XCart`, given a camera intrinsics matrix `K` and an extrinsics matrix `T`.\n",
    "\n",
    "The second component is a method to estimate a Eucledian transformation, `TEst`, that takes us from a plane's 3D coordinate space to 3D camera space by utilizing a given set of points in camera image space, `XImCart`, and a set of corresponding points in world space, `XCart`. Essentially we want to compute the extrinsics matrix we can use in `projectiveCamera`.\n",
    "\n",
    "Estimating the camera pose will involve calculating a homography, so you'll need to copy over your functions from part 1A/1B in the space provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectiveCamera(K,T,XCart):\n",
    "    ##TODO\n",
    "    # The goal of this function is to project points in XCart through projective camera\n",
    "    # defined by intrinsic matrix K and extrinsic matrix T. In essence, this function takes a set of points \n",
    "    # in 3D world space, XCart, and projects them into camera image space by applying the extrinsic matrix T \n",
    "    # and then applying the intrinsic matrix K.\n",
    "    # \n",
    "    # There are three steps.\n",
    "    # 1) Move from world space to camera space. \n",
    "    #            camera space points = extrinsics T * world space points \n",
    "    #\n",
    "    # 2) Applying the intrinsics matrix to the camera space points after normalizing\n",
    "    #           homogeneous image space points = K * normalized camera space points\n",
    "    # \n",
    "    # 3) Move to image space cartesian points from image space homogeneous points, involves a \n",
    "    # normalization using the third row.\n",
    "    \n",
    "    \n",
    "    # TODO: Replace this\n",
    "    XImCart = []\n",
    "\n",
    "    # TODO: Convert Cartesian 3d points XCart to homogeneous coordinates XHom\n",
    "    XHom = np.concatenate((XCart, np.ones((1,XCart.shape[1]))), axis=0);\n",
    "    # TODO: Apply extrinsic matrix to XHom, to move to frame of reference of camera\n",
    "    xCamHom = np.matmul(T,XHom);\n",
    "    # TODO: Project points into normalized camera coordinates xCamHom (remove 4th row)\n",
    "    xCamHom = xCamHom[0:3, :];\n",
    "    # TODO: Move points to image coordinates xImHom by applying intrinsic matrix\n",
    "    xCamHom = np.matmul(K,xCamHom);\n",
    "    # TODO: Convert points back to Cartesian coordinates xImCart\n",
    "    XImCart = xCamHom[0:2,:] / np.tile([xCamHom[2,:]],(2,1));\n",
    "    return XImCart\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Projection\n",
    "\n",
    "First we'll write up the function that can take us from 3D world space, `XCart`, to camera image space, `XImCart`, using an extrinsics matrix `T` and an intrinsics matrix `K` that are provided. The previous block houses this function.\n",
    "\n",
    "The result here is the cartesian image space point coordinates, `XImCart`, of the 3D points `XCart`. If `XCart` represents a box in the world then we now know where the box's vertices would land in image space.\n",
    "\n",
    "To verify that your solution is correct please compare your image space points to those in the comment.\n",
    "\n",
    "Once they match, move on to the next bit - estimating a transformation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[267.4170882  230.95045427 531.42492013 482.36049098 378.77537982]\n",
      " [396.26814909 288.11435494 237.83410247 358.39940241 329.44079538]]\n"
     ]
    }
   ],
   "source": [
    "# We assume that the camera intrinsics matrix K is known and has values:\n",
    "K = np.array([[640, 0, 320],\n",
    "             [0, 640, 240],\n",
    "             [0, 0, 1]])\n",
    "\n",
    "# We will assume an object co-ordinate system with the Z-axis pointing upwards and the origin\n",
    "# in the centre of the plane. There are five known points on the plane with coordinates (mm):\n",
    "XCart = np.array([[-100, -100,  100,  100, 0],\n",
    "                  [-100,  100,  100, -100, 0],\n",
    "                  [   0,    0,    0,    0, 0]])\n",
    "\n",
    "# We assume the correct transformation from the plane co-ordinate system to the\n",
    "# camera co-ordinate system (extrinsic matrix) is:\n",
    "T = np.array([[0.9851,  -0.0492,  0.1619,  46.00],\n",
    "             [-0.1623,  -0.5520,  0.8181,  70.00],\n",
    "             [0.0490,  -0.8324, -0.5518,  500.89],\n",
    "             [0,        0,       0,       1]])\n",
    "# T houses a rotation matrix and a translation matrix. The last row is for homogeneous point calculation.\n",
    "\n",
    "\n",
    "# TODO: Use the general pin-hole projective camera model discussed in the lectures to estimate \n",
    "# where the four points on the plane will appear in the image.  Fill in the\n",
    "# details of the function \"projectiveCamera\"\n",
    "XImCart = projectiveCamera(K,T,XCart)\n",
    "\n",
    "print(XImCart)\n",
    "# Should be around:\n",
    "# [267.4170882  230.95045427 531.42492013 482.36049098 378.77537982]\n",
    "# [396.26814909 288.11435494 237.83410247 358.39940241 329.44079538]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image space points match perfectly with those in the comments which verifies my solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You've implemented both of these functions in 1A and 1B already, so feel free to copy them in here. You'll need them for this next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solveAXEqualsZero(A):\n",
    "    # TODO: Write this routine - it should solve Ah = 0. You can do this using SVD. Consult your notes! \n",
    "    # Hint: SVD will be involved. \n",
    "    U, L, VT = np.linalg.svd(A)\n",
    "    V = VT.T\n",
    "    h = V[:,-1]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcBestHomography(pts1Cart, pts2Cart):\n",
    "    \n",
    "    # This function should apply the direct linear transform (DLT) algorithm to calculate the best \n",
    "    # homography that maps the cartesian points in pts1Cart to their corresonding matching cartesian poitns \n",
    "    # in pts2Cart.\n",
    "    \n",
    "    # This function calls solveAXEqualsZero. Make sure you are wary of how to reshape h into a 3 by 3 matrix. \n",
    "\n",
    "    n_points = pts1Cart.shape[1]\n",
    "    \n",
    "    # TODO: replace this:\n",
    "    H = np.identity(3)\n",
    "\n",
    "    # TODO: \n",
    "    # First convert points into homogeneous representation\n",
    "    # Hint: we've done this before  in the skeleton code we provide.\n",
    "    pts1Hom = np.concatenate((pts1Cart, np.ones((1,pts1Cart.shape[1]))), axis=0)\n",
    "    pts2Hom = np.concatenate((pts2Cart, np.ones((1,pts2Cart.shape[1]))), axis=0)\n",
    "    \n",
    "    # Then construct the matrix A, size (n_points * 2, 9)\n",
    "    # Consult the notes!\n",
    "    n_points = pts1Cart.shape[1]\n",
    "\n",
    "    A = np.zeros((2*n_points,9))\n",
    "    \n",
    "    for point in range(n_points):\n",
    "        #first row in each pair of rows of A\n",
    "        A[2*point, 3:6] = -1*pts1Hom[:,point]\n",
    "        A[2*point, 6:9] = pts2Hom[1,point]*pts1Hom[:,point]\n",
    "\n",
    "        #second row in each pair of rows of A\n",
    "        A[2*point + 1, 0:3] = pts1Hom[:,point]\n",
    "        A[2*point + 1, 6:9] = -1*pts2Hom[0,point]*pts1Hom[:,point]\n",
    "\n",
    "\n",
    "\n",
    "    # Solve Ah = 0 using solveAXEqualsZero and get h.\n",
    "    h = solveAXEqualsZero(A)\n",
    "    # Reshape h into the matrix H, values of h go first into rows of H\n",
    "    H = np.reshape(h, (3,3))\n",
    "    \n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the next cell first for context!\n",
    "\n",
    "def estimatePlanePose(XImCart,XCart,K):\n",
    "    # The goal of this function is to estimate the pose of a plane relative to camera (extrinsic matrix)\n",
    "    # given points in image space xImCart, points in 3D world space XCart, and an intrinsics matrix K.\n",
    "    \n",
    "    # TODO: replace this\n",
    "    T = np.zeros((4,4))\n",
    "\n",
    "    # TODO: Convert Cartesian image points XImCart to homogeneous representation XImHom\n",
    "    XImHom = np.concatenate((XImCart, np.ones((1,XImCart.shape[1]))), axis=0)\n",
    "    \n",
    "    # TODO: Convert image co-ordinates XImHom to normalized camera coordinates XCamHom    \n",
    "    XCamHom = np.matmul(np.linalg.inv(K),XImHom)\n",
    "    \n",
    "    # TODO: Estimate homography H mapping homogeneous (x,y) coordinates of positions\n",
    "    # in real world to XCamHom (convert XCamHom to Cartesian, calculate the homography) -\n",
    "    # use the routine you wrote for Practical 1B\n",
    "\n",
    "    XCamHomCart = XCamHom[0:2,:] / np.tile([XCamHom[2,:]],(2,1))\n",
    "    H = calcBestHomography(XCart[0:2,:],XCamHomCart)\n",
    "          \n",
    "    # TODO: Estimate first two columns of rotation matrix R from the first two\n",
    "    # columns of H using the SVD. NOTE: You do not need to transpose v from linalg.svd    \n",
    "    U, L, VT = np.linalg.svd(H[:,:2])\n",
    "    I = np.eye(3)\n",
    "    R = I.copy()\n",
    "    R[:,:2] = U @ I[:,:2] @ VT\n",
    "\n",
    "    # TODO: Estimate the third column of the rotation matrix by taking the cross\n",
    "    # product of the first two columns\n",
    "    R[:,2] = np.cross(R[:,0],R[:,1])\n",
    "        \n",
    "    # TODO: Check that the determinant of the rotation matrix is positive - if\n",
    "    # not then multiply last column by -1.\n",
    "    if(np.linalg.det(R)<=0):\n",
    "        R[:,2] = R[:,2] * -1\n",
    "    \n",
    "    # TODO: Estimate the translation t by finding the appropriate scaling factor k\n",
    "    # and applying it to the third colulmn of H\n",
    "    k = np.sum(H[:,:2]/R[:,:2])/6\n",
    "    t = H[:,[-1]]/k\n",
    "    # TODO: Check whether t_z is negative - if it is then multiply t by -1 and\n",
    "    # the first two columns of R by -1.\n",
    "    if(t[-1,:]<0):\n",
    "        t = t * -1\n",
    "        R[:,:2] = R[:,:2] * -1\n",
    "            \n",
    "    # TODO: Assemble transformation into matrix form\n",
    "    T[:-1, :-1] = R\n",
    "    T[:-1, [-1]] = t\n",
    "    T[-1,-1] = 1\n",
    "    return T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the juicy bit: Estimating an Extrinsics Matrix, T\n",
    "\n",
    "The problem: We are given an instrinsics matrix `K`, a set of 3D world points `XCart`, and a set of corresponding image space coordinates in `XImCart`. `K` and `XCart` have already been defined a few cells back and you've calculated `XImCart` by virtue of the exercise you've completed with camera projection. What we don't have is an extrinsics matrix, `T`. We need to estimate this and you'll need to fill in `estimatePlanePose` and return `TEst`.\n",
    "\n",
    "Again you can start by negating the noise we add to XImCart to make sure you're on the right track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.860e-01 -6.909e-02  1.515e-01  4.935e+01]\n",
      " [-1.646e-01 -5.404e-01  8.251e-01  7.624e+01]\n",
      " [ 2.484e-02 -8.386e-01 -5.442e-01  5.452e+02]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  1.000e+00]]\n",
      "\n",
      "\n",
      "[[ 9.851e-01 -4.920e-02  1.619e-01  4.600e+01]\n",
      " [-1.623e-01 -5.520e-01  8.181e-01  7.000e+01]\n",
      " [ 4.900e-02 -8.324e-01 -5.518e-01  5.009e+02]\n",
      " [ 0.000e+00  0.000e+00  0.000e+00  1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add noise (standard deviation of one pixel in each direction) to the pixel positions\n",
    "# to simulate having to find these points in a noisy image. Store the results back in xImCart\n",
    "noise = np.random.normal(0,1, XImCart.shape)\n",
    "XImCartNoisy = XImCart + noise#add noise here\n",
    "\n",
    "\n",
    "# TODO: Now we will take the image points and the known positions on the card and estimate  \n",
    "# the extrinsic matrix using the algorithm discussed in the lecture.  Fill in the details of \n",
    "# the function estimatePlanePose\n",
    "TEst = estimatePlanePose(XImCartNoisy,XCart,K)\n",
    "\n",
    "# If you have got this correct, TEst should closely resemble the groundtruth, T.\n",
    "np.set_printoptions(precision=3)\n",
    "print(TEst)\n",
    "print(\"\\n\")\n",
    "print(T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.096 -40.428   6.451  -7.288]\n",
      " [ -1.422   2.101  -0.862  -8.915]\n",
      " [ 49.312  -0.741   1.371  -8.85 ]]\n"
     ]
    }
   ],
   "source": [
    "print(100*(T[:-1,:]-TEst[:-1,:])/T[:-1,:]) #checking % error of estimated matrix entries. Last row ignored because will trivially match due to design."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adding noise, the ground truth and extimated matrices have similar matrix entries(and matching entries have same order of magnitude). During my multiple runs by hand, I noticed that the 2 entries in row=1, column=2 and in row=3,column=1 which have ground truth values -4.920e-02 and 4.900e-02 respectively, usually tend to have the biggest percentage estimation error. I suspect this is due to them being the two smallest entries in ground truth matrix T."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3dd5ba0fcdb24de16818bfb70fb7995edac6a09e5545214c1bd690016a414ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
